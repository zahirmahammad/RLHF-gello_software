{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7978fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mROBOMIMIC WARNING(\n",
      "    No private macro file found!\n",
      "    It is recommended to use a private macro file\n",
      "    To setup, run: python /home/sj/Assistive_Feeding_Gello/robomimic/robomimic/scripts/setup_macros.py\n",
      ")\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import glob \n",
    "\n",
    "import torch\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.torch_utils as TorchUtils\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.envs.env_base import EnvBase\n",
    "from robomimic.algo import RolloutPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1a59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1204,  0.2657,  0.2955],\n",
      "        [-0.1545,  0.2626,  0.2830],\n",
      "        [-0.1877,  0.2607,  0.2674],\n",
      "        [-0.1980,  0.2624,  0.2602],\n",
      "        [-0.2140,  0.2667,  0.2443],\n",
      "        [-0.2224,  0.2733,  0.2333],\n",
      "        [-0.2246,  0.2846,  0.2215],\n",
      "        [-0.2266,  0.2924,  0.2148],\n",
      "        [-0.2289,  0.2977,  0.2108],\n",
      "        [-0.2268,  0.3061,  0.2087],\n",
      "        [-0.2260,  0.3132,  0.2064],\n",
      "        [-0.2274,  0.3180,  0.2040],\n",
      "        [-0.2253,  0.3273,  0.2022],\n",
      "        [-0.2268,  0.3341,  0.1985],\n",
      "        [-0.2304,  0.3382,  0.1955],\n",
      "        [-0.2329,  0.3406,  0.1939],\n",
      "        [-0.2370,  0.3441,  0.1906],\n",
      "        [-0.2393,  0.3456,  0.1886],\n",
      "        [-0.2425,  0.3469,  0.1863],\n",
      "        [-0.2435,  0.3464,  0.1857],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852],\n",
      "        [-0.2437,  0.3465,  0.1852]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_folder = \"/home/sj/Assistive_Feeding_Gello/csv/diffstartsamegoalsp100/pose/test\"\n",
    "end_eff_folder = \"/home/sj/Assistive_Feeding_Gello/csv/diffstartsamegoalsp100/end_eff/test\"\n",
    "\n",
    "csv_files = glob.glob(os.path.join(csv_folder, '*.csv'))\n",
    "end_eff_files = glob.glob(os.path.join(end_eff_folder, '*.csv'))\n",
    "\n",
    "low_dim_data = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for csv_file, end_eff_file in zip(csv_files, end_eff_files):\n",
    "        joint_data = pd.read_csv(csv_file, usecols=range(0, 6), engine='python').astype(np.float64)\n",
    "        end_eff_pos_data = pd.read_csv(end_eff_file, usecols=range(0, 3), engine='python').astype(np.float64)\n",
    "        end_eff_quat_data = pd.read_csv(end_eff_file, usecols=range(3, 7), engine='python').astype(np.float64)\n",
    "\n",
    "        joint_data = torch.tensor(joint_data.values).float().to(device)\n",
    "        end_eff_pos_data = torch.tensor(end_eff_pos_data.values).float().to(device)\n",
    "        end_eff_quat_data = torch.tensor(end_eff_quat_data.values).float().to(device)\n",
    "\n",
    "# obs = {\"robot0_joint_pos\": joint_data, \"robot0_eef_pos\": end_eff_pos_data, \"robot0_eef_quat\": end_eff_quat_data}\n",
    "# print(obs[\"robot0_joint_pos\"].shape, obs[\"robot0_eef_pos\"].shape, obs[\"robot0_eef_quat\"].shape)\n",
    "\n",
    "obs = {\"robot0_eef_pos\": end_eff_pos_data}\n",
    "print(obs[\"robot0_eef_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01cb3dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sj/Assistive_Feeding_Gello/robomimic/robomimic/utils/file_utils.py\n"
     ]
    }
   ],
   "source": [
    "import robomimic.utils.file_utils as FileUtils\n",
    "\n",
    "print(FileUtils.policy_from_checkpoint.__code__.co_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7911d9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
      "using obs modality: rgb with keys: []\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    }
   ],
   "source": [
    "# ckpt_path = \"/home/sj/assistive_feed_gello/Assistive_Feeding_Gello/robomimic/bc_trained_models/allready2/20240607064247/models/model_epoch_100.pth\"\n",
    "ckpt_path = \"/home/sj/Assistive_Feeding_Gello/robomimic/bc_trained_models/allready2/20240614134639/models/model_epoch_100.pth\"\n",
    "# Restore policy\n",
    "policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b17bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "here\n",
      "Action [-0.15126228  0.26834363  0.2825454 ] \n",
      " robot0_eef_pos tensor([-0.1204,  0.2657,  0.2955])\n",
      "here\n",
      "Action [-0.24301934  0.17695466  0.33015922] \n",
      " robot0_eef_pos tensor([-0.1545,  0.2626,  0.2830])\n",
      "here\n",
      "Action [-0.34224385  0.08305949  0.34605002] \n",
      " robot0_eef_pos tensor([-0.1877,  0.2607,  0.2674])\n",
      "here\n",
      "Action [-0.43279582  0.05720739  0.3427731 ] \n",
      " robot0_eef_pos tensor([-0.1980,  0.2624,  0.2602])\n",
      "here\n",
      "Action [-0.5275444   0.08220584  0.3355908 ] \n",
      " robot0_eef_pos tensor([-0.2140,  0.2667,  0.2443])\n",
      "here\n",
      "Action [-0.6220171   0.15642616  0.3203317 ] \n",
      " robot0_eef_pos tensor([-0.2224,  0.2733,  0.2333])\n",
      "here\n",
      "Action [-0.700884    0.25900736  0.28815028] \n",
      " robot0_eef_pos tensor([-0.2246,  0.2846,  0.2215])\n",
      "here\n",
      "Action [-0.7674148   0.37972966  0.2459637 ] \n",
      " robot0_eef_pos tensor([-0.2266,  0.2924,  0.2148])\n",
      "here\n",
      "Action [-0.8141836   0.48501003  0.20192659] \n",
      " robot0_eef_pos tensor([-0.2289,  0.2977,  0.2108])\n",
      "here\n",
      "Action [-0.84422714  0.569193    0.15694411] \n",
      " robot0_eef_pos tensor([-0.2268,  0.3061,  0.2087])\n",
      "here\n",
      "Action [-0.86970687  0.6407204   0.11535994] \n",
      " robot0_eef_pos tensor([-0.2260,  0.3132,  0.2064])\n",
      "here\n",
      "Action [-0.89081544  0.6924049   0.08911999] \n",
      " robot0_eef_pos tensor([-0.2274,  0.3180,  0.2040])\n",
      "here\n",
      "Action [-0.9051635   0.73247117  0.06624255] \n",
      " robot0_eef_pos tensor([-0.2253,  0.3273,  0.2022])\n",
      "here\n",
      "Action [-0.9160656   0.7666478   0.04416288] \n",
      " robot0_eef_pos tensor([-0.2268,  0.3341,  0.1985])\n",
      "here\n",
      "Action [-0.92447263  0.79485625  0.02551937] \n",
      " robot0_eef_pos tensor([-0.2304,  0.3382,  0.1955])\n",
      "here\n",
      "Action [-0.9313824   0.8180398   0.01146287] \n",
      " robot0_eef_pos tensor([-0.2329,  0.3406,  0.1939])\n",
      "here\n",
      "Action [-0.9375975   0.83840185  0.00102022] \n",
      " robot0_eef_pos tensor([-0.2370,  0.3441,  0.1906])\n",
      "here\n",
      "Action [-0.9430821   0.8557673  -0.00679158] \n",
      " robot0_eef_pos tensor([-0.2393,  0.3456,  0.1886])\n",
      "here\n",
      "Action [-0.94776934  0.8694432  -0.01166659] \n",
      " robot0_eef_pos tensor([-0.2425,  0.3469,  0.1863])\n",
      "here\n",
      "Action [-0.9516804   0.8798698  -0.01408805] \n",
      " robot0_eef_pos tensor([-0.2435,  0.3464,  0.1857])\n",
      "here\n",
      "Action [-0.9547909   0.8875868  -0.01504681] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.95715606  0.8930989  -0.01543811] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9588807   0.89693904 -0.01555584] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9600974  0.8995513 -0.0155945] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9609314   0.9012865  -0.01562099] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9614893   0.902414   -0.01565469] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.96185476  0.9031316  -0.0156955 ] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.96208954  0.90357894 -0.01573833] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9622378   0.9038521  -0.01577817] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.9623299   0.9040155  -0.01581243] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "torch.Size([1, 3])\n",
      "here\n",
      "Action [-0.24453838  0.34901395  0.18586649] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.50715184  0.43797967  0.15099353] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.71114576  0.58433616  0.13605054] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n",
      "here\n",
      "Action [-0.8301457   0.7028717   0.12059157] \n",
      " robot0_eef_pos tensor([-0.2437,  0.3465,  0.1852])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(obs[\"robot0_eef_pos\"])):\n",
    "    obs_to_pass = {\"robot0_eef_pos\": obs[\"robot0_eef_pos\"][i]}\n",
    "    # obs_to_pass = {\"robot0_eef_pos\": torch.tensor(obs[\"robot0_eef_pos\"][0]).to(device)}\n",
    "    # print(obs_to_pass[\"robot0_eef_pos\"])\n",
    "    # policy, ckpt_dict = FileUtils.policy_from_checkpoint(ckpt_path=ckpt_path, device=device, verbose=True)\n",
    "    with torch.no_grad():\n",
    "        action = policy(obs_to_pass)\n",
    "        print(\"Action\", action, \"\\n\", \"robot0_eef_pos\", obs_to_pass[\"robot0_eef_pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186964bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(obs[\"robot0_joint_pos\"])):\n",
    "    obs_to_pass = {\"robot0_joint_pos\": obs[\"robot0_joint_pos\"][i], \"robot0_eef_pos\": obs[\"robot0_eef_pos\"][i], \"robot0_eef_quat\": obs[\"robot0_eef_quat\"][i]}\n",
    "    print(obs_to_pass[\"robot0_joint_pos\"])\n",
    "    action = policy(obs_to_pass)\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f238e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_from_policy(policy, obs):\n",
    "    # Get action from policy\n",
    "    action = policy(obs)\n",
    "    print(action)\n",
    "    return action\n",
    "\n",
    "for i in range(len(obs[\"robot0_eef_pos\"])):\n",
    "    if i==0:\n",
    "        obs_to_pass = {\"robot0_eef_pos\": obs[\"robot0_eef_pos\"]}\n",
    "        print(i, \"obs_to_pass\", obs_to_pass[\"robot0_eef_pos\"])\n",
    "        action = policy(obs_to_pass)\n",
    "        print(i, \"action\", action)\n",
    "        continue\n",
    "    print(\"i\", i)\n",
    "    obs_to_pass = {\"robot0_eef_pos\": action}\n",
    "    print(i, \"obs_to_pass\", obs_to_pass[\"robot0_eef_pos\"])\n",
    "    action = policy(obs_to_pass)\n",
    "    print(i, \"action\", action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/home/sj/Downloads/split_part2.hdf5\"\n",
    "\n",
    "num = 2\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as f:\n",
    "    # Iterate through each demo group\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]\n",
    "        \n",
    "    # #     # Access the corner2_image dataset within the obs group of the demo group\n",
    "        image_data = demo_group['obs']['corner2_image'][:]\n",
    "        \n",
    "        # Perform the operation on the image array\n",
    "        image_data = np.array(image_data)\n",
    "\n",
    "        print(image_data.shape)\n",
    "\n",
    "        for i in range(14):\n",
    "            image_data = np.insert(image_data, num, image_data[num - 1], axis=0)\n",
    "            num += 2\n",
    "\n",
    "        num = 2\n",
    "\n",
    "        # Delete the existing corner2_image dataset\n",
    "        del demo_group['obs']['corner2_image']\n",
    "        \n",
    "        # Rename the \"images\" dataset as \"corner2_image\"\n",
    "        demo_group[\"obs\"].create_dataset(\"corner2_image\", data=image_data)\n",
    "\n",
    "\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]        # Now working on manipulating the split_data\n",
    "\n",
    "        state_data = demo_group['states'][:]\n",
    "\n",
    "        num = 2\n",
    "\n",
    "        new_state_data = np.empty((state_data.shape[0] + 14, state_data.shape[1]))\n",
    "\n",
    "        for i in range(14):\n",
    "            state_data_plus1  = state_data[num+1]\n",
    "            state_data_minus1 = state_data[num-1]\n",
    "\n",
    "            new_state_data[num] = (state_data_plus1 + state_data_minus1) / 2\n",
    "\n",
    "            state_data = np.insert(state_data, num, new_state_data[num], axis=0)\n",
    "            num += 2\n",
    "\n",
    "        num = 2\n",
    "    # print(new_state_data.shape)\n",
    "    # print(state_data.shape)\n",
    "\n",
    "        # Delete the existing states dataset\n",
    "        del demo_group['states']\n",
    "\n",
    "        # # Create a new dataset with the new state data\n",
    "        demo_group.create_dataset(\"states\", data=new_state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14499ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"/home/sj/Downloads/split_part1.hdf5\"\n",
    "# Open the HDF5 file\n",
    "with h5py.File(file_path, 'a') as f:\n",
    "    # Iterate through each demo group\n",
    "    for demo_name in f[\"data\"].keys():\n",
    "        demo_group = f['data'][demo_name]\n",
    "        \n",
    "    # #     # Access the corner2_image dataset within the obs group of the demo group\n",
    "        image_data = demo_group['obs']['corner2_image'][:]\n",
    "        \n",
    "        # Perform the operation on the image array\n",
    "        image_data = np.array(image_data)\n",
    "        labels = np.zeros((len(image_data), 1, 96, 96))\n",
    "        labels[14:] = 1\n",
    "        # image_data = np.concatenate((image_data, labels), axis=1)\n",
    "        # demo_group[\"obs\"].create_dataset(\"images\", data=image_data)\n",
    "\n",
    "        # # Delete the existing corner2_image dataset\n",
    "        # del demo_group['obs']['corner2_image']\n",
    "        \n",
    "        # # Rename the \"images\" dataset as \"corner2_image\"\n",
    "        # demo_group[\"obs\"].move(\"images\", \"corner2_image\")\n",
    "\n",
    "    #     print(image_data.shape)\n",
    "\n",
    "        # Now working on manipulating the split_data\n",
    "        state_data = demo_group['states'][-1, :3]\n",
    "        new_state_data = np.zeros((len(state_data), 3))\n",
    "        new_state_data[:] = state_data\n",
    "        # print(state_data)\n",
    "\n",
    "        new_state_data = np.concatenate((demo_group['states'], new_state_data), axis=-1)\n",
    "        print(new_state_data.shape)\n",
    "\n",
    "        # Delete the existing states dataset\n",
    "        del demo_group['states']\n",
    "\n",
    "        # Create a new dataset with the new state data\n",
    "        demo_group.create_dataset(\"states\", data=new_state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0752d18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def test_connection(ip, port):\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            s.connect((ip, port))\n",
    "            print(f\"Successfully connected to {ip} on port {port}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to {ip} on port {port}: {e}\")\n",
    "\n",
    "# IP address of the robot or gripper\n",
    "ip_address = \"192.168.77.21\"\n",
    "\n",
    "# Test common ports\n",
    "ports = [502, 29999, 30001, 30002, 30003]\n",
    "for port in ports:\n",
    "    test_connection(ip_address, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424cfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
